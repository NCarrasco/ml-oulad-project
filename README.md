# Machine Learning â€“ OULAD Project

Este repositorio contiene el desarrollo completo del proyecto final colaborativo de la asignatura **Ciencia de Datos I** de la MaestrÃ­a en Ciencia de Datos e Inteligencia Artificial (UASD). Se aplica Machine Learning para analizar el desempeÃ±o acadÃ©mico de estudiantes, utilizando el dataset OULAD y un dataset complementario basado en SABER11/SABERPRO.

## ğŸ¯ Objetivo

Construir modelos predictivos que identifiquen patrones de Ã©xito acadÃ©mico y participaciÃ³n estudiantil, utilizando variables sociodemogrÃ¡ficas, acadÃ©micas y de interacciÃ³n (clickstream).

## ğŸ“¦ Estructura del Proyecto

```
ml-oulad-project/
â”‚
â”œâ”€â”€ config/           â†’ ConfiguraciÃ³n de conexiÃ³n (settings.py)
â”œâ”€â”€ data/             â†’ (VacÃ­a por defecto) Carpeta para datasets locales (opcional)
â”œâ”€â”€ src/              â†’ Scripts Python (pipeline principal, mÃ³dulos y utilidades)
â”‚   â”œâ”€â”€ oulad_pipeline.py
â”‚   â”œâ”€â”€ db_connector.py
â”‚   â”œâ”€â”€ db_queries.py
â”‚   â”œâ”€â”€ eda.py
â”‚   â”œâ”€â”€ preprocess.py
â”‚   â”œâ”€â”€ models/
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ notebooks/        â†’ (VacÃ­a por defecto) Jupyter/Colab para EDA y experimentos (opcional)
â”œâ”€â”€ docs/             â†’ (VacÃ­a por defecto) ArtÃ­culo cientÃ­fico (APA) y anexos
â”œâ”€â”€ results/          â†’ CSV, mÃ©tricas, grÃ¡ficos finales
â”œâ”€â”€ schema.sql        â†’ (Opcional) Script SQL si se usÃ³ RDBMS
â”œâ”€â”€ requirements.txt  â†’ LibrerÃ­as necesarias
â””â”€â”€ README.md         â†’ Este archivo
```

## âš™ï¸ InstalaciÃ³n y configuraciÃ³n

1. **Clona el repositorio y accede a la carpeta:**
   ```bash
   git clone <url-del-repo>
   cd ml-oulad-project
   ```
2. **Crea un entorno virtual (opcional pero recomendado):**
   ```bash
   python3 -m venv venv
   source venv/bin/activate
   ```
3. **Instala las dependencias:**
   ```bash
   pip install -r requirements.txt
   ```
4. **Configura la conexiÃ³n a MySQL:**
   - Edita `config/settings.py` con tus credenciales y nombre de base de datos.
   - Ejemplo de cadena de conexiÃ³n:
     ```python
     SQLALCHEMY_URL = "mysql+mysqlconnector://usuario:contraseÃ±a@localhost/ouladdb"
     ```

## ğŸ—„ï¸ Exportar el esquema de la base de datos (opcional)

Si necesitas exportar solo el esquema (sin datos):
```bash
mysqldump -u <usuario> -p --no-data ouladdb > schema.sql
```

Si tu base de datos estÃ¡ en Docker, ejecuta este comando (ajusta el nombre del contenedor si es necesario):

```bash
docker exec -i <nombre_contenedor_mysql> mysqldump -u root -p --no-data ouladdb > esquema_ouladdb.sql
```

Por ejemplo, si tu contenedor se llama `mysql-oulad`:

```bash
docker exec -i mysql-sakila mysqldump -u root -p --no-data ouladdb > esquema_ouladdb.sql
```

Cuando pida la contraseÃ±a, ingresa la que corresponda (por defecto: xxxxx).

## ğŸš€ EjecuciÃ³n del pipeline principal

1. AsegÃºrate de que la base de datos MySQL estÃ© activa y accesible.
2. Ejecuta el pipeline desde la terminal (puedes limitar el tamaÃ±o para pruebas rÃ¡pidas):
   ```bash
   python src/oulad_pipeline.py --max_rows 20000
   ```
   - El parÃ¡metro `--max_rows` permite trabajar con un subconjunto aleatorio del dataset para acelerar pruebas y evitar problemas de memoria en equipos personales.
   - Por defecto, el pipeline usa 100,000 filas si no se especifica.
3. Los resultados (mÃ©tricas, grÃ¡ficos, predicciones, clustering) se guardarÃ¡n en la carpeta `results/`.

## ğŸ§  TecnologÃ­as utilizadas

- Python 3.x
- Pandas, NumPy, Scikit-learn, Matplotlib, Seaborn
- SQLAlchemy, tqdm, imbalanced-learn
- Google Colab / Visual Studio Code
- MySQL (opcional)

## ğŸ“Š MetodologÃ­a

- Pipeline OSEMN: Obtener, Seleccionar, Explorar, Modelar, Comunicar
- EDA: univariado, bivariado, boxplots, correlaciones, kurtosis
- ML supervisado: RegresiÃ³n logÃ­stica, Random Forest, SVM
- MÃ©tricas: Accuracy, Precision, Recall, F1, ROC-AUC, MSE, RÂ²
- Visualizaciones y anÃ¡lisis de variables mÃ¡s influyentes

## ğŸ“ˆ Salidas esperadas

- Predicciones (`y_test`, `y_pred`) exportadas a CSV
- CÃ¡lculo manual del F1-score (TP, FP, TN, FN)
- Visualizaciones: matriz de confusiÃ³n, scatter, importancias

## ğŸ‘¥ Autores y colaboraciÃ³n

- Norman Carrasco
- Miguel Pimentel
- Miguel Consoro

Ver detalles de roles y aportes en el docstring de `src/oulad_pipeline.py`.

---

## ğŸ‘¥ DistribuciÃ³n de Tareas

Este proyecto fue desarrollado de forma colaborativa, con la siguiente divisiÃ³n de responsabilidades:

| Etapa | Tarea                                              | Responsable         | Fecha lÃ­mite |
|-------|----------------------------------------------------|---------------------|--------------|
| 1     | DefiniciÃ³n de hipÃ³tesis y objetivos                | Todos               | 22-jun       |
| 2     | Complementar dataset OULAD con fuentes adicionales | Norman Carrasco     | 24-jun       |
| 3     | Limpieza y codificaciÃ³n de datos                   | Norman Carrasco     | 26-jun       |
| 4     | AnÃ¡lisis exploratorio (EDA)                        | Norman Carrasco     | 27-jun       |
| 5     | Entrenamiento de modelos ML                        | Norman Carrasco     | 28-jun       |
| 6     | ValidaciÃ³n de modelos                              | Miguel Pimentel     | 29-jun       |
| 7     | EvaluaciÃ³n final de mÃ©tricas                       | Miguel Consoro      | 30-jun       |
| 8     | ExportaciÃ³n de resultados                          | Norman Carrasco     | 30-jun       |
| 9     | Visualizaciones finales                            | Miguel Pimentel     | 01-jul       |
| 10    | RedacciÃ³n del artÃ­culo                             | Miguel Consoro      | 02-jul       |
| 11    | Formato APA y referencias                          | Miguel Consoro      | 03-jul       |
| 12    | DocumentaciÃ³n tÃ©cnica del cÃ³digo                   | Norman Carrasco     | 03-jul       |
| 13    | RevisiÃ³n final del entregable                      | Todos               | 04-jul       |

## ğŸ“„ Licencia

Uso exclusivamente acadÃ©mico. No comercial.

---

## ğŸ› ï¸ Uso avanzado y troubleshooting

- **EjecuciÃ³n directa:**
  - Ejecuta el pipeline completo desde terminal con:
    ```bash
    python src/oulad_pipeline.py
    ```
  - Si usas Docker para MySQL, asegÃºrate de que el contenedor estÃ© corriendo y la configuraciÃ³n en `config/settings.py` apunte al host/puerto correcto.
- **Reproducibilidad:**
  - El pipeline es completamente reproducible usando solo `requirements.txt` y la configuraciÃ³n indicada.
  - Todos los resultados se generan en la carpeta `results/`.
- **InterpretaciÃ³n de resultados:**
  - Los archivos CSV y PNG generados pueden ser usados como anexos en artÃ­culos cientÃ­ficos.
  - Las mÃ©tricas manuales (`metrics_manual.csv`) incluyen TP, FP, TN, FN, F1, accuracy, precision, recall, MSE, RÂ².

## ğŸ“‚ Tabla de outputs generados

| Archivo/GrÃ¡fico                  | DescripciÃ³n                                      |
|----------------------------------|--------------------------------------------------|
| y_test_y_pred.csv                | Predicciones y valores reales                    |
| metrics_manual.csv               | MÃ©tricas manuales de clasificaciÃ³n/regresiÃ³n     |
| confusion_matrix.png             | Matriz de confusiÃ³n visual                       |
| feature_importances.png          | Importancia de variables (modelos de Ã¡rbol)      |
| metrics_classifiers.csv          | MÃ©tricas de validaciÃ³n cruzada (clasificadores)  |
| metrics_regressors.csv           | MÃ©tricas de validaciÃ³n cruzada (regresores)      |
| kmeans_elbow.png                 | GrÃ¡fico del mÃ©todo del codo (clustering)         |
| random_projection_gaussian.png   | ProyecciÃ³n aleatoria 2D de los datos             |

## ğŸ“Š Visualizaciones generadas

A continuaciÃ³n se muestran ejemplos de los grÃ¡ficos generados automÃ¡ticamente en la carpeta `results/`:

| Boxplot por mÃ³dulo | Boxplot por fecha | Boxplot por resultado final |
|--------------------|-------------------|----------------------------|
| ![boxplot_code_module](results/boxplot_code_module.png) | ![boxplot_date](results/boxplot_date.png) | ![boxplot_final_result](results/boxplot_final_result.png) |

| Histograma resultado final | Heatmap de correlaciÃ³n | Scatter final_result vs Withdrawn |
|---------------------------|------------------------|-----------------------------------|
| ![hist_final_result](results/hist_final_result.png) | ![correlation_heatmap](results/correlation_heatmap.png) | ![scatter_final_result_vs_FResult02_Withdrawn](results/scatter_final_result_vs_FResult02_Withdrawn.png) |

## â“ Preguntas frecuentes (FAQ)

- **Error de conexiÃ³n a MySQL:**
  - Verifica usuario, contraseÃ±a, host y puerto en `config/settings.py`.
  - Si usas Docker, expÃ³n el puerto 3306 y revisa el nombre del contenedor.
- **Faltan dependencias:**
  - Ejecuta `pip install -r requirements.txt`.
- **No se generan archivos en `results/`:**
  - Verifica permisos de escritura y que la ruta exista.
- **Â¿CÃ³mo interpreto las mÃ©tricas?**
  - Consulta la secciÃ³n de outputs y la documentaciÃ³n del notebook para ejemplos y explicaciones.

> Para dudas adicionales, revisa los comentarios en el cÃ³digo y el notebook de ejemplo.

## ğŸ“‰ Visualizaciones avanzadas y anÃ¡lisis de errores

- **Curva ROC:**
  - EvalÃºa la capacidad de discriminaciÃ³n del modelo en clasificaciÃ³n binaria.
  - Ejemplo de cÃ³digo:
    ```python
    from sklearn.metrics import roc_curve, auc
    y_score = modelo.predict_proba(X_test)[:,1]
    fpr, tpr, _ = roc_curve(y_test, y_score)
    auc_score = auc(fpr, tpr)
    ```
- **Interpretabilidad con SHAP:**
  - Explica el aporte de cada variable a la predicciÃ³n de modelos de Ã¡rbol.
  - Ejemplo de cÃ³digo:
    ```python
    import shap
    explainer = shap.TreeExplainer(modelo)
    shap_values = explainer.shap_values(X_test)
    shap.summary_plot(shap_values, X_test)
    ```
- **Matriz de confusiÃ³n normalizada:**
  - Permite analizar los errores relativos por clase.
  - Ejemplo de cÃ³digo:
    ```python
    from sklearn.metrics import ConfusionMatrixDisplay
    ConfusionMatrixDisplay.from_estimator(modelo, X_test, y_test, normalize='true')
    ```

> Estas visualizaciones pueden ser incluidas como anexos o figuras en el informe cientÃ­fico para enriquecer la interpretaciÃ³n de resultados.
